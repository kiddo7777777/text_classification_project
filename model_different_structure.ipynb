{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5c75581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "584f775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a02ce543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68d06db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.read_csv('SBIC.v2.trn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faa754f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>whoTarget</th>\n",
       "      <th>intentYN</th>\n",
       "      <th>sexYN</th>\n",
       "      <th>sexReason</th>\n",
       "      <th>offensiveYN</th>\n",
       "      <th>annotatorGender</th>\n",
       "      <th>annotatorMinority</th>\n",
       "      <th>sexPhrase</th>\n",
       "      <th>speakerMinorityYN</th>\n",
       "      <th>WorkerId</th>\n",
       "      <th>HITId</th>\n",
       "      <th>annotatorPolitics</th>\n",
       "      <th>annotatorRace</th>\n",
       "      <th>annotatorAge</th>\n",
       "      <th>post</th>\n",
       "      <th>targetMinority</th>\n",
       "      <th>targetCategory</th>\n",
       "      <th>targetStereotype</th>\n",
       "      <th>dataSource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>woman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8935932304856669427</td>\n",
       "      <td>363A7XIFV4G2799C5V96YERJA9AVAM</td>\n",
       "      <td>liberal</td>\n",
       "      <td>white</td>\n",
       "      <td>45.0</td>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t/davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>man</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6347880360297734464</td>\n",
       "      <td>363A7XIFV4G2799C5V96YERJA9AVAM</td>\n",
       "      <td>mod-liberal</td>\n",
       "      <td>white</td>\n",
       "      <td>35.0</td>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t/davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>man</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7452610791699819066</td>\n",
       "      <td>363A7XIFV4G2799C5V96YERJA9AVAM</td>\n",
       "      <td>liberal</td>\n",
       "      <td>asian</td>\n",
       "      <td>23.0</td>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t/davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>man</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-500114755446676507</td>\n",
       "      <td>3JTPR5MTZS6RLS3JBV4IOU0G2X35K5</td>\n",
       "      <td>liberal</td>\n",
       "      <td>white</td>\n",
       "      <td>25.0</td>\n",
       "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You f...</td>\n",
       "      <td>black folks</td>\n",
       "      <td>race</td>\n",
       "      <td>all stupid</td>\n",
       "      <td>t/davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>man</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-500114755446676507</td>\n",
       "      <td>3JTPR5MTZS6RLS3JBV4IOU0G2X35K5</td>\n",
       "      <td>liberal</td>\n",
       "      <td>white</td>\n",
       "      <td>25.0</td>\n",
       "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You f...</td>\n",
       "      <td>black folks</td>\n",
       "      <td>race</td>\n",
       "      <td>are not people but apes.</td>\n",
       "      <td>t/davidson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   whoTarget  intentYN  sexYN sexReason  offensiveYN annotatorGender  \\\n",
       "0        0.0      0.66    0.0       NaN          1.0           woman   \n",
       "1        0.0      0.66    0.0       NaN          0.5             man   \n",
       "2        0.0      0.33    0.0       NaN          0.5             man   \n",
       "3        1.0      1.00    0.0       NaN          1.0             man   \n",
       "4        1.0      1.00    0.0       NaN          1.0             man   \n",
       "\n",
       "  annotatorMinority sexPhrase  speakerMinorityYN             WorkerId  \\\n",
       "0               NaN       NaN                NaN -8935932304856669427   \n",
       "1               NaN       NaN                NaN  6347880360297734464   \n",
       "2               NaN       NaN                NaN -7452610791699819066   \n",
       "3               NaN       NaN                0.0  -500114755446676507   \n",
       "4               NaN       NaN                0.0  -500114755446676507   \n",
       "\n",
       "                            HITId annotatorPolitics annotatorRace  \\\n",
       "0  363A7XIFV4G2799C5V96YERJA9AVAM           liberal         white   \n",
       "1  363A7XIFV4G2799C5V96YERJA9AVAM       mod-liberal         white   \n",
       "2  363A7XIFV4G2799C5V96YERJA9AVAM           liberal         asian   \n",
       "3  3JTPR5MTZS6RLS3JBV4IOU0G2X35K5           liberal         white   \n",
       "4  3JTPR5MTZS6RLS3JBV4IOU0G2X35K5           liberal         white   \n",
       "\n",
       "   annotatorAge                                               post  \\\n",
       "0          45.0  RT @_LexC__: I'm convinced that some of y'all ...   \n",
       "1          35.0  RT @_LexC__: I'm convinced that some of y'all ...   \n",
       "2          23.0  RT @_LexC__: I'm convinced that some of y'all ...   \n",
       "3          25.0  RT @iBeZo: Stupid fucking nigger LeBron. You f...   \n",
       "4          25.0  RT @iBeZo: Stupid fucking nigger LeBron. You f...   \n",
       "\n",
       "  targetMinority targetCategory          targetStereotype  dataSource  \n",
       "0            NaN            NaN                       NaN  t/davidson  \n",
       "1            NaN            NaN                       NaN  t/davidson  \n",
       "2            NaN            NaN                       NaN  t/davidson  \n",
       "3    black folks           race                all stupid  t/davidson  \n",
       "4    black folks           race  are not people but apes.  t/davidson  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc39d4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple = df_trn[['post','offensiveYN']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42e0a0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>offensiveYN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You f...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You f...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post  offensiveYN\n",
       "0  RT @_LexC__: I'm convinced that some of y'all ...          1.0\n",
       "1  RT @_LexC__: I'm convinced that some of y'all ...          0.5\n",
       "2  RT @_LexC__: I'm convinced that some of y'all ...          0.5\n",
       "3  RT @iBeZo: Stupid fucking nigger LeBron. You f...          1.0\n",
       "4  RT @iBeZo: Stupid fucking nigger LeBron. You f...          1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82d031cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @_LexC__: I\\'m convinced that some of y\\'all bitches get pregnant purposely because \"birth control &amp; plan b pills\" are effective &#128533;&#128056;&#9749;&#65039;'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simple['post'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99ec378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_simple['post_split']=[len(x.split(sep)) for x in df_simple['post']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07aedf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_simple[df_simple['post_split']>2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b97d4afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sep = ': '\n",
    "# stripped = x.split(sep, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0755e02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d61ea77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a29cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_simple.iloc[118,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cde7e0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"RT @prettykells: &#8220;@100046729: That's fucked up when a bitch you fw , down talk you.. Then with hoes they claim they don't fw &#128080; funny.&#8221;&#8252;&#65039;&#8252;&#65039;&#8230;\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08c00358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's fucked up when a bitch you fw , down talk you.. Then with hoes they claim they don't fw &#128080; funny.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = '^RT.*: '\n",
    "pattern_2 ='&#[^a-zA-Z]+;$'\n",
    "re.sub(pattern_2,'',re.sub(pattern,'',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fceffa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple['clean_post']=[re.sub(pattern_2,'',re.sub(pattern,'',x)) for x in df_simple['post']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25d82d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple['label']= [x if x!=0.5 else 3 for x in df_simple['offensiveYN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8d9c913",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>offensiveYN</th>\n",
       "      <th>clean_post</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I'm convinced that some of y'all bitches get p...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>I'm convinced that some of y'all bitches get p...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>I'm convinced that some of y'all bitches get p...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You f...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Stupid fucking nigger LeBron. You flopping stu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You f...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Stupid fucking nigger LeBron. You flopping stu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112895</th>\n",
       "      <td>Thought you fellas might like to explain to so...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thought you fellas might like to explain to so...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112896</th>\n",
       "      <td>Thought you fellas might like to explain to so...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thought you fellas might like to explain to so...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112897</th>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112898</th>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112899</th>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112900 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     post  offensiveYN  \\\n",
       "0       RT @_LexC__: I'm convinced that some of y'all ...          1.0   \n",
       "1       RT @_LexC__: I'm convinced that some of y'all ...          0.5   \n",
       "2       RT @_LexC__: I'm convinced that some of y'all ...          0.5   \n",
       "3       RT @iBeZo: Stupid fucking nigger LeBron. You f...          1.0   \n",
       "4       RT @iBeZo: Stupid fucking nigger LeBron. You f...          1.0   \n",
       "...                                                   ...          ...   \n",
       "112895  Thought you fellas might like to explain to so...          1.0   \n",
       "112896  Thought you fellas might like to explain to so...          0.0   \n",
       "112897  If female voters were discounted, Labour would...          0.0   \n",
       "112898  If female voters were discounted, Labour would...          0.0   \n",
       "112899  If female voters were discounted, Labour would...          0.5   \n",
       "\n",
       "                                               clean_post  label  \n",
       "0       I'm convinced that some of y'all bitches get p...    1.0  \n",
       "1       I'm convinced that some of y'all bitches get p...    3.0  \n",
       "2       I'm convinced that some of y'all bitches get p...    3.0  \n",
       "3       Stupid fucking nigger LeBron. You flopping stu...    1.0  \n",
       "4       Stupid fucking nigger LeBron. You flopping stu...    1.0  \n",
       "...                                                   ...    ...  \n",
       "112895  Thought you fellas might like to explain to so...    1.0  \n",
       "112896  Thought you fellas might like to explain to so...    0.0  \n",
       "112897  If female voters were discounted, Labour would...    0.0  \n",
       "112898  If female voters were discounted, Labour would...    0.0  \n",
       "112899  If female voters were discounted, Labour would...    3.0  \n",
       "\n",
       "[112900 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec4218e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d8f801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple.to_csv('trn_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "202e7a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple = pd.read_csv('trn_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6931912e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>post</th>\n",
       "      <th>offensiveYN</th>\n",
       "      <th>clean_post</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I'm convinced that some of y'all bitches get p...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>I'm convinced that some of y'all bitches get p...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>I'm convinced that some of y'all bitches get p...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You f...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Stupid fucking nigger LeBron. You flopping stu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You f...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Stupid fucking nigger LeBron. You flopping stu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               post  offensiveYN  \\\n",
       "0           0  RT @_LexC__: I'm convinced that some of y'all ...          1.0   \n",
       "1           1  RT @_LexC__: I'm convinced that some of y'all ...          0.5   \n",
       "2           2  RT @_LexC__: I'm convinced that some of y'all ...          0.5   \n",
       "3           3  RT @iBeZo: Stupid fucking nigger LeBron. You f...          1.0   \n",
       "4           4  RT @iBeZo: Stupid fucking nigger LeBron. You f...          1.0   \n",
       "\n",
       "                                          clean_post  label  \n",
       "0  I'm convinced that some of y'all bitches get p...    1.0  \n",
       "1  I'm convinced that some of y'all bitches get p...    3.0  \n",
       "2  I'm convinced that some of y'all bitches get p...    3.0  \n",
       "3  Stupid fucking nigger LeBron. You flopping stu...    1.0  \n",
       "4  Stupid fucking nigger LeBron. You flopping stu...    1.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72af1025",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df_simple['clean_post'].values\n",
    "y = df_simple['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "911230c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train,sentences_test,y_train,y_test = train_test_split(\n",
    "                                                sentences, y,  \n",
    "                                                test_size=0.20,  \n",
    "                                                random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe93613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(sentences_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d7a9ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
    "X_test = tokenizer.texts_to_sequences(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e858bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f8cd7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d917a537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  \n",
    "    # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word] \n",
    "                embedding_matrix[idx] = np.array(\n",
    "                                        vector, dtype=np.float32)[:embedding_dim]\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bedf3054",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "embedding_matrix = create_embedding_matrix('glove.6B.50d.txt' ,\n",
    "                                            tokenizer.word_index,  \n",
    "                                            embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b562f84f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:755 train_step\n        loss = self.compiled_loss(\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:1537 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:4833 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-c4c114ef6103>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m---> 15\u001b[0;31m history = model.fit(X_train, y_train,\n\u001b[0m\u001b[1;32m     16\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:755 train_step\n        loss = self.compiled_loss(\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:1537 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:4833 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /home/haolunzhang/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 1) and (None, 3) are incompatible\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "embedding_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=5,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3812c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55851eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1762acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6aa2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63265e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb38003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f1b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52ccca6a",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19dcc658",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple = pd.read_csv('trn_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9df437fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>post</th>\n",
       "      <th>offensiveYN</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I'm convinced that some of y'all bitches get p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I'm convinced that some of y'all bitches get p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I'm convinced that some of y'all bitches get p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You f...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Stupid fucking nigger LeBron. You flopping stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You f...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Stupid fucking nigger LeBron. You flopping stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112895</th>\n",
       "      <td>112895</td>\n",
       "      <td>Thought you fellas might like to explain to so...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thought you fellas might like to explain to so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112896</th>\n",
       "      <td>112896</td>\n",
       "      <td>Thought you fellas might like to explain to so...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thought you fellas might like to explain to so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112897</th>\n",
       "      <td>112897</td>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112898</th>\n",
       "      <td>112898</td>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112899</th>\n",
       "      <td>112899</td>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112900 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               post  \\\n",
       "0                0  RT @_LexC__: I'm convinced that some of y'all ...   \n",
       "1                1  RT @_LexC__: I'm convinced that some of y'all ...   \n",
       "2                2  RT @_LexC__: I'm convinced that some of y'all ...   \n",
       "3                3  RT @iBeZo: Stupid fucking nigger LeBron. You f...   \n",
       "4                4  RT @iBeZo: Stupid fucking nigger LeBron. You f...   \n",
       "...            ...                                                ...   \n",
       "112895      112895  Thought you fellas might like to explain to so...   \n",
       "112896      112896  Thought you fellas might like to explain to so...   \n",
       "112897      112897  If female voters were discounted, Labour would...   \n",
       "112898      112898  If female voters were discounted, Labour would...   \n",
       "112899      112899  If female voters were discounted, Labour would...   \n",
       "\n",
       "        offensiveYN  label                                         clean_post  \n",
       "0               1.0    1.0  I'm convinced that some of y'all bitches get p...  \n",
       "1               0.5    3.0  I'm convinced that some of y'all bitches get p...  \n",
       "2               0.5    3.0  I'm convinced that some of y'all bitches get p...  \n",
       "3               1.0    1.0  Stupid fucking nigger LeBron. You flopping stu...  \n",
       "4               1.0    1.0  Stupid fucking nigger LeBron. You flopping stu...  \n",
       "...             ...    ...                                                ...  \n",
       "112895          1.0    1.0  Thought you fellas might like to explain to so...  \n",
       "112896          0.0    0.0  Thought you fellas might like to explain to so...  \n",
       "112897          0.0    0.0  If female voters were discounted, Labour would...  \n",
       "112898          0.0    0.0  If female voters were discounted, Labour would...  \n",
       "112899          0.5    3.0  If female voters were discounted, Labour would...  \n",
       "\n",
       "[112900 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e27e6eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_agg_alan = df_simple.groupby(by=[\"clean_post\"]).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b967f91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "513f21c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_simple.groupby(by=[\"clean_post\"]).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b36c142a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_post</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>post</th>\n",
       "      <th>offensiveYN</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nBill Kristol and Ben Shaprio, two turds in...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nRose\\nðŸŒ¹Taylorâ€ @RealRoseTaylor 6h6 hours a...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nCharlie Kirkâ€\\n\\nJohnny Depp calls for death...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDavid Knightâ€ \\n\\nNotice how quickly things ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nFinland fireball: Time-lapse video shows nig...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\nICE\\n\\nâ€œTodayâ€™s actions send a strong messag...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\nIf family \"A\" went on a 2 month vacation,\\na...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\\nIsaiah 26:3\\nYou will keep in perfect peace ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\nJust watched facial recognition technology f...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nMany serial killers and all-around psychopat...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>\\nShock Claim: Mystery planet might crash and ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\\nYou Tube has Censored our Channel because we...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>\\nCharlie Kirk\\n\\nEvery college socialist sho...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>\"Love is like the wind, you can't see it but ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@MadJewessWoman \\nI crushed it so it wilted y...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Breaking911\\n\\nBREAKING: 3 heavily armed gunm...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Breitbart is pro-Israel/ jew, that automatica...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Donald J. Trumpâ€\\n\\nIf last nightâ€™s election ...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Even if you believe Moore is innocent, you do...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Fox Newsâ€\\n\\nGOPLeader: \"For every American t...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           clean_post  Unnamed: 0  post  \\\n",
       "0   \\n\\nBill Kristol and Ben Shaprio, two turds in...           3     3   \n",
       "1   \\n\\nRose\\nðŸŒ¹Taylorâ€ @RealRoseTaylor 6h6 hours a...           3     3   \n",
       "2   \\nCharlie Kirkâ€\\n\\nJohnny Depp calls for death...           2     2   \n",
       "3   \\nDavid Knightâ€ \\n\\nNotice how quickly things ...           3     3   \n",
       "4   \\nFinland fireball: Time-lapse video shows nig...           3     3   \n",
       "5   \\nICE\\n\\nâ€œTodayâ€™s actions send a strong messag...           3     3   \n",
       "6   \\nIf family \"A\" went on a 2 month vacation,\\na...           3     3   \n",
       "7   \\nIsaiah 26:3\\nYou will keep in perfect peace ...           3     3   \n",
       "8   \\nJust watched facial recognition technology f...           7     7   \n",
       "9   \\nMany serial killers and all-around psychopat...           3     3   \n",
       "10  \\nShock Claim: Mystery planet might crash and ...           3     3   \n",
       "11  \\nYou Tube has Censored our Channel because we...           3     3   \n",
       "12   \\nCharlie Kirk\\n\\nEvery college socialist sho...           3     3   \n",
       "13   \"Love is like the wind, you can't see it but ...           3     3   \n",
       "14   @MadJewessWoman \\nI crushed it so it wilted y...           3     3   \n",
       "15   Breaking911\\n\\nBREAKING: 3 heavily armed gunm...           3     3   \n",
       "16   Breitbart is pro-Israel/ jew, that automatica...           3     3   \n",
       "17   Donald J. Trumpâ€\\n\\nIf last nightâ€™s election ...           3     3   \n",
       "18   Even if you believe Moore is innocent, you do...           3     3   \n",
       "19   Fox Newsâ€\\n\\nGOPLeader: \"For every American t...           3     3   \n",
       "\n",
       "    offensiveYN  label  \n",
       "0             3      3  \n",
       "1             3      3  \n",
       "2             2      2  \n",
       "3             3      3  \n",
       "4             3      3  \n",
       "5             3      3  \n",
       "6             3      3  \n",
       "7             3      3  \n",
       "8             7      7  \n",
       "9             3      3  \n",
       "10            3      3  \n",
       "11            3      3  \n",
       "12            3      3  \n",
       "13            3      3  \n",
       "14            3      3  \n",
       "15            3      3  \n",
       "16            2      2  \n",
       "17            3      3  \n",
       "18            3      3  \n",
       "19            3      3  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c30eb3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_post</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>post</th>\n",
       "      <th>offensiveYN</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\nJust watched facial recognition technology f...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I propose a new law \\n\\n Any congressman or w...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Just a partial list of the Dem playbook\\n\\nfo...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>all the liberals who are saying to get rid of...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35459</th>\n",
       "      <td>â€œYou can drink an ugly woman pretty, faster th...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35460</th>\n",
       "      <td>â€œYou da bomb!â€ â€œNo, you da bomb!â€ In America â€“...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35470</th>\n",
       "      <td>â€¼ï¸PRANK ALERT â€¼ï¸ THIS WEEKS #DolanTwinsNewVide...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35471</th>\n",
       "      <td>â Why do wh*te people like to play hockey?  Itâ€™...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35482</th>\n",
       "      <td>âš½ï¸ POLL: After an eventful day in the #Champio...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6320 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clean_post  Unnamed: 0  post  \\\n",
       "8      \\nJust watched facial recognition technology f...           7     7   \n",
       "20      I propose a new law \\n\\n Any congressman or w...           6     6   \n",
       "23      Just a partial list of the Dem playbook\\n\\nfo...           5     5   \n",
       "26      all the liberals who are saying to get rid of...           4     4   \n",
       "29     !!! RT @mayasolovely: As a woman you shouldn't...           4     4   \n",
       "...                                                  ...         ...   ...   \n",
       "35459  â€œYou can drink an ugly woman pretty, faster th...           6     6   \n",
       "35460  â€œYou da bomb!â€ â€œNo, you da bomb!â€ In America â€“...           6     6   \n",
       "35470  â€¼ï¸PRANK ALERT â€¼ï¸ THIS WEEKS #DolanTwinsNewVide...           6     6   \n",
       "35471  â Why do wh*te people like to play hockey?  Itâ€™...           4     4   \n",
       "35482  âš½ï¸ POLL: After an eventful day in the #Champio...           6     6   \n",
       "\n",
       "       offensiveYN  label  \n",
       "8                7      7  \n",
       "20               6      6  \n",
       "23               5      5  \n",
       "26               4      4  \n",
       "29               4      4  \n",
       "...            ...    ...  \n",
       "35459            6      6  \n",
       "35460            6      6  \n",
       "35470            6      6  \n",
       "35471            4      4  \n",
       "35482            6      6  \n",
       "\n",
       "[6320 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg[df_agg['post']>3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6087826",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_agg['post'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38d6b6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2017 na value for offensiveYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d810544",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple = df_simple[df_simple['offensiveYN'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60143782",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_simple.groupby(by=[\"clean_post\"])['offensiveYN'].agg(lambda x:pd.Series.mode(x)[0]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcaf4e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_post</th>\n",
       "      <th>offensiveYN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nBill Kristol and Ben Shaprio, two turds in...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nRose\\nðŸŒ¹Taylorâ€ @RealRoseTaylor 6h6 hours a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nCharlie Kirkâ€\\n\\nJohnny Depp calls for death...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDavid Knightâ€ \\n\\nNotice how quickly things ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nFinland fireball: Time-lapse video shows nig...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35415</th>\n",
       "      <td>ðŸ‘‰ Illegally in the country after 5 deportation...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35416</th>\n",
       "      <td>ðŸ’¥BreakingðŸ’¥\\nJulian Assange is the gate keeper ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35417</th>\n",
       "      <td>ðŸ“– 2Kings 22:19  because your heart was peniten...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35418</th>\n",
       "      <td>ðŸš¨#FAKENEWSAWARDSðŸš¨\\n\\nðŸš¨ who isÂ #1Â fake news ?ðŸš¨\\...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35419</th>\n",
       "      <td>ðŸš¨BREAKING: illegal alien 5x deported on 7 felo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35420 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clean_post  offensiveYN\n",
       "0      \\n\\nBill Kristol and Ben Shaprio, two turds in...          1.0\n",
       "1      \\n\\nRose\\nðŸŒ¹Taylorâ€ @RealRoseTaylor 6h6 hours a...          0.0\n",
       "2      \\nCharlie Kirkâ€\\n\\nJohnny Depp calls for death...          1.0\n",
       "3      \\nDavid Knightâ€ \\n\\nNotice how quickly things ...          0.0\n",
       "4      \\nFinland fireball: Time-lapse video shows nig...          0.0\n",
       "...                                                  ...          ...\n",
       "35415  ðŸ‘‰ Illegally in the country after 5 deportation...          0.0\n",
       "35416  ðŸ’¥BreakingðŸ’¥\\nJulian Assange is the gate keeper ...          0.0\n",
       "35417  ðŸ“– 2Kings 22:19  because your heart was peniten...          0.0\n",
       "35418  ðŸš¨#FAKENEWSAWARDSðŸš¨\\n\\nðŸš¨ who isÂ #1Â fake news ?ðŸš¨\\...          0.0\n",
       "35419  ðŸš¨BREAKING: illegal alien 5x deported on 7 felo...          1.0\n",
       "\n",
       "[35420 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cc00f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg_mode2 = df_simple.groupby(by=[\"clean_post\"])['offensiveYN'].agg(pd.Series.mode).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd483008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_post</th>\n",
       "      <th>offensiveYN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\nMany serial killers and all-around psychopat...</td>\n",
       "      <td>[0.0, 0.5, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>\\nYou Tube has Censored our Channel because we...</td>\n",
       "      <td>[0.0, 0.5, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Isnâ€™t it weird that in America, our flag and ...</td>\n",
       "      <td>[0.0, 0.5, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>[0.5, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>\" So hoes that smoke are losers ? \" yea ... go...</td>\n",
       "      <td>[0.0, 0.5, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35347</th>\n",
       "      <td>â€œI hope Trump is assassinated!â€ - Maria Chappe...</td>\n",
       "      <td>[0.0, 0.5, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35383</th>\n",
       "      <td>â€œYou incels are such LOSERS!â€\\n\\- normie spend...</td>\n",
       "      <td>[0.0, 0.5, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35389</th>\n",
       "      <td>â€ªSome nations die in flames and screams.â€¬\\n\\nâ€ª...</td>\n",
       "      <td>[0.0, 0.5, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35398</th>\n",
       "      <td>â˜ŠOh great. The person who took twelve minutes ...</td>\n",
       "      <td>[0.0, 0.5, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35418</th>\n",
       "      <td>ðŸš¨#FAKENEWSAWARDSðŸš¨\\n\\nðŸš¨ who isÂ #1Â fake news ?ðŸš¨\\...</td>\n",
       "      <td>[0.0, 0.5, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2431 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clean_post      offensiveYN\n",
       "9      \\nMany serial killers and all-around psychopat...  [0.0, 0.5, 1.0]\n",
       "11     \\nYou Tube has Censored our Channel because we...  [0.0, 0.5, 1.0]\n",
       "22      Isnâ€™t it weird that in America, our flag and ...  [0.0, 0.5, 1.0]\n",
       "29     !!! RT @mayasolovely: As a woman you shouldn't...       [0.5, 1.0]\n",
       "32     \" So hoes that smoke are losers ? \" yea ... go...  [0.0, 0.5, 1.0]\n",
       "...                                                  ...              ...\n",
       "35347  â€œI hope Trump is assassinated!â€ - Maria Chappe...  [0.0, 0.5, 1.0]\n",
       "35383  â€œYou incels are such LOSERS!â€\\n\\- normie spend...  [0.0, 0.5, 1.0]\n",
       "35389  â€ªSome nations die in flames and screams.â€¬\\n\\nâ€ª...  [0.0, 0.5, 1.0]\n",
       "35398  â˜ŠOh great. The person who took twelve minutes ...  [0.0, 0.5, 1.0]\n",
       "35418  ðŸš¨#FAKENEWSAWARDSðŸš¨\\n\\nðŸš¨ who isÂ #1Â fake news ?ðŸš¨\\...  [0.0, 0.5, 1.0]\n",
       "\n",
       "[2431 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = [0,0.5,1]\n",
    "multi_mode = df_agg_mode2[~df_agg_mode2.offensiveYN.isin(values)]\n",
    "multi_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cf23077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2431"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(multi_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b896c4b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        \\n\\nBill Kristol and Ben Shaprio, two turds in...\n",
       "1        \\n\\nRose\\nðŸŒ¹Taylorâ€ @RealRoseTaylor 6h6 hours a...\n",
       "2        \\nCharlie Kirkâ€\\n\\nJohnny Depp calls for death...\n",
       "3        \\nDavid Knightâ€ \\n\\nNotice how quickly things ...\n",
       "4        \\nFinland fireball: Time-lapse video shows nig...\n",
       "                               ...                        \n",
       "35415    ðŸ‘‰ Illegally in the country after 5 deportation...\n",
       "35416    ðŸ’¥BreakingðŸ’¥\\nJulian Assange is the gate keeper ...\n",
       "35417    ðŸ“– 2Kings 22:19  because your heart was peniten...\n",
       "35418    ðŸš¨#FAKENEWSAWARDSðŸš¨\\n\\nðŸš¨ who isÂ #1Â fake news ?ðŸš¨\\...\n",
       "35419    ðŸš¨BREAKING: illegal alien 5x deported on 7 felo...\n",
       "Name: clean_post, Length: 35420, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg['clean_post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9347987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg['label']= [x if x!=0.5 else 3 for x in df_agg['offensiveYN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b566073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c049156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df_agg['clean_post'].values\n",
    "#y = df_agg['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fa2ba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df_agg['label'].values)\n",
    "#test_y = le.transform(test_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d35a14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99a46da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train,sentences_test,y_train,y_test = train_test_split(\n",
    "                                                sentences, y,  \n",
    "                                                test_size=0.20,  \n",
    "                                                random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e1d2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 3)\n",
    "y_test = to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e359aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b40f9065",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(sentences_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b47da98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
    "X_test = tokenizer.texts_to_sequences(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4eeef786",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1d68adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4490d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  \n",
    "    # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word] \n",
    "                embedding_matrix[idx] = np.array(\n",
    "                                        vector, dtype=np.float32)[:embedding_dim]\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d13b3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "embedding_matrix = create_embedding_matrix('glove.6B.50d.txt' ,\n",
    "                                            tokenizer.word_index,  \n",
    "                                            embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38fdf14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  = Conv1D(128, 3, activation='relu')(x)\n",
    "# x = MaxPooling1D(3)(x)\n",
    "# x = Conv1D(128, 3, activation='relu')(x)\n",
    "# x = MaxPooling1D(3)(x)\n",
    "# x = Conv1D(128, 3, activation='relu')(x)\n",
    "# x = GlobalMaxPooling1D()(x)\n",
    "# x = Dense(128, activation='relu')(x)\n",
    "# output = Dense(len(possible_labels), activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9fea49c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5668/5668 [==============================] - 1089s 192ms/step - loss: 2.8098 - accuracy: 0.4967 - val_loss: 0.8880 - val_accuracy: 0.4963\n",
      "Epoch 2/5\n",
      "5668/5668 [==============================] - 1067s 188ms/step - loss: 0.8904 - accuracy: 0.5060 - val_loss: 0.8916 - val_accuracy: 0.4963\n",
      "Epoch 3/5\n",
      "5668/5668 [==============================] - 1073s 189ms/step - loss: 0.8961 - accuracy: 0.4987 - val_loss: 0.8886 - val_accuracy: 0.4963\n",
      "Epoch 4/5\n",
      "5668/5668 [==============================] - 1089s 192ms/step - loss: 0.8931 - accuracy: 0.5030 - val_loss: 0.8851 - val_accuracy: 0.4963\n",
      "Epoch 5/5\n",
      "5668/5668 [==============================] - 1126s 199ms/step - loss: 0.8914 - accuracy: 0.5031 - val_loss: 0.8857 - val_accuracy: 0.4963\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "embedding_dim = 100\n",
    "\n",
    "# layer = layers.Dense(\n",
    "#     units=64,\n",
    "#     kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "#     bias_regularizer=regularizers.l2(1e-4),\n",
    "#     activity_regularizer=regularizers.l2(1e-5)\n",
    "# )\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "# model.add(layers.MaxPooling2D(pool_size=(2,2), strides=(1,1), padding=\"same\"))\n",
    "model.add(layers.Dense(5, kernel_initializer='ones',\n",
    "                          kernel_regularizer=tf.keras.regularizers.l1(0.01),\n",
    "                          activity_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(layers.Dense(128, activation='relu',  \n",
    "                       kernel_regularizer=tf.keras.regularizers.l1(0.01),     \n",
    "                       activity_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(layers.Dense(3, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=5,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6f3ee98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### incorporate numeric features/ categorical features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb65c67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
