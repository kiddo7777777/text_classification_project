{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5c75581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "584f775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a02ce543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca975ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4d2d5a4",
   "metadata": {},
   "source": [
    "### Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68d06db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.read_csv('SBF_trn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faa754f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>whoTarget</th>\n",
       "      <th>intentYN</th>\n",
       "      <th>sexYN</th>\n",
       "      <th>sexReason</th>\n",
       "      <th>offensiveYN</th>\n",
       "      <th>annotatorGender</th>\n",
       "      <th>annotatorMinority</th>\n",
       "      <th>sexPhrase</th>\n",
       "      <th>speakerMinorityYN</th>\n",
       "      <th>WorkerId</th>\n",
       "      <th>HITId</th>\n",
       "      <th>annotatorPolitics</th>\n",
       "      <th>annotatorRace</th>\n",
       "      <th>annotatorAge</th>\n",
       "      <th>post</th>\n",
       "      <th>targetMinority</th>\n",
       "      <th>targetCategory</th>\n",
       "      <th>targetStereotype</th>\n",
       "      <th>dataSource</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>woman</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-8935932304856669427</td>\n",
       "      <td>363A7XIFV4G2799C5V96YERJA9AVAM</td>\n",
       "      <td>liberal</td>\n",
       "      <td>white</td>\n",
       "      <td>45.0</td>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t/davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>man</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6347880360297734464</td>\n",
       "      <td>363A7XIFV4G2799C5V96YERJA9AVAM</td>\n",
       "      <td>mod-liberal</td>\n",
       "      <td>white</td>\n",
       "      <td>35.0</td>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t/davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>man</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7452610791699819066</td>\n",
       "      <td>363A7XIFV4G2799C5V96YERJA9AVAM</td>\n",
       "      <td>liberal</td>\n",
       "      <td>asian</td>\n",
       "      <td>23.0</td>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t/davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>man</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-500114755446676507</td>\n",
       "      <td>3JTPR5MTZS6RLS3JBV4IOU0G2X35K5</td>\n",
       "      <td>liberal</td>\n",
       "      <td>white</td>\n",
       "      <td>25.0</td>\n",
       "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You f...</td>\n",
       "      <td>black folks</td>\n",
       "      <td>race</td>\n",
       "      <td>all stupid</td>\n",
       "      <td>t/davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>man</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-500114755446676507</td>\n",
       "      <td>3JTPR5MTZS6RLS3JBV4IOU0G2X35K5</td>\n",
       "      <td>liberal</td>\n",
       "      <td>white</td>\n",
       "      <td>25.0</td>\n",
       "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You f...</td>\n",
       "      <td>black folks</td>\n",
       "      <td>race</td>\n",
       "      <td>are not people but apes.</td>\n",
       "      <td>t/davidson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   whoTarget  intentYN  sexYN sexReason  offensiveYN annotatorGender  \\\n",
       "0        0.0      0.66    0.0       NaN          1.0           woman   \n",
       "1        0.0      0.66    0.0       NaN          0.5             man   \n",
       "2        0.0      0.33    0.0       NaN          0.5             man   \n",
       "3        1.0      1.00    0.0       NaN          1.0             man   \n",
       "4        1.0      1.00    0.0       NaN          1.0             man   \n",
       "\n",
       "  annotatorMinority sexPhrase  speakerMinorityYN             WorkerId  \\\n",
       "0               NaN       NaN                NaN -8935932304856669427   \n",
       "1               NaN       NaN                NaN  6347880360297734464   \n",
       "2               NaN       NaN                NaN -7452610791699819066   \n",
       "3               NaN       NaN                0.0  -500114755446676507   \n",
       "4               NaN       NaN                0.0  -500114755446676507   \n",
       "\n",
       "                            HITId annotatorPolitics annotatorRace  \\\n",
       "0  363A7XIFV4G2799C5V96YERJA9AVAM           liberal         white   \n",
       "1  363A7XIFV4G2799C5V96YERJA9AVAM       mod-liberal         white   \n",
       "2  363A7XIFV4G2799C5V96YERJA9AVAM           liberal         asian   \n",
       "3  3JTPR5MTZS6RLS3JBV4IOU0G2X35K5           liberal         white   \n",
       "4  3JTPR5MTZS6RLS3JBV4IOU0G2X35K5           liberal         white   \n",
       "\n",
       "   annotatorAge                                               post  \\\n",
       "0          45.0  RT @_LexC__: I'm convinced that some of y'all ...   \n",
       "1          35.0  RT @_LexC__: I'm convinced that some of y'all ...   \n",
       "2          23.0  RT @_LexC__: I'm convinced that some of y'all ...   \n",
       "3          25.0  RT @iBeZo: Stupid fucking nigger LeBron. You f...   \n",
       "4          25.0  RT @iBeZo: Stupid fucking nigger LeBron. You f...   \n",
       "\n",
       "  targetMinority targetCategory          targetStereotype  dataSource  \n",
       "0            NaN            NaN                       NaN  t/davidson  \n",
       "1            NaN            NaN                       NaN  t/davidson  \n",
       "2            NaN            NaN                       NaN  t/davidson  \n",
       "3    black folks           race                all stupid  t/davidson  \n",
       "4    black folks           race  are not people but apes.  t/davidson  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc39d4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple = df_trn[['post','offensiveYN']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42e0a0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>offensiveYN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You f...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You f...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                post  offensiveYN\n",
       "0  RT @_LexC__: I'm convinced that some of y'all ...          1.0\n",
       "1  RT @_LexC__: I'm convinced that some of y'all ...          0.5\n",
       "2  RT @_LexC__: I'm convinced that some of y'all ...          0.5\n",
       "3  RT @iBeZo: Stupid fucking nigger LeBron. You f...          1.0\n",
       "4  RT @iBeZo: Stupid fucking nigger LeBron. You f...          1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82d031cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @_LexC__: I\\'m convinced that some of y\\'all bitches get pregnant purposely because \"birth control &amp; plan b pills\" are effective &#128533;&#128056;&#9749;&#65039;'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simple['post'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "99ec378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple['post_split']=[len(x.split(sep)) for x in df_simple['post']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07aedf12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>offensiveYN</th>\n",
       "      <th>post_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>RT @prettykells: &amp;#8220;@100046729: That's fuc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>RT @prettykells: &amp;#8220;@100046729: That's fuc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>RT @prettykells: &amp;#8220;@100046729: That's fuc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>RT @prettykells: &amp;#8220;@100046729: That's fuc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>RT @VineForTheByrd: Bae: go text your hoes \\nM...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111926</th>\n",
       "      <td>Who are your favourite and least favourite inc...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112123</th>\n",
       "      <td>I will date ANY femoid: they CANNOT be forever...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112124</th>\n",
       "      <td>I will date ANY femoid: they CANNOT be forever...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112125</th>\n",
       "      <td>I will date ANY femoid: they CANNOT be forever...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112126</th>\n",
       "      <td>I will date ANY femoid: they CANNOT be forever...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2264 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     post  offensiveYN  \\\n",
       "118     RT @prettykells: &#8220;@100046729: That's fuc...          1.0   \n",
       "119     RT @prettykells: &#8220;@100046729: That's fuc...          1.0   \n",
       "120     RT @prettykells: &#8220;@100046729: That's fuc...          1.0   \n",
       "121     RT @prettykells: &#8220;@100046729: That's fuc...          1.0   \n",
       "236     RT @VineForTheByrd: Bae: go text your hoes \\nM...          0.0   \n",
       "...                                                   ...          ...   \n",
       "111926  Who are your favourite and least favourite inc...          0.0   \n",
       "112123  I will date ANY femoid: they CANNOT be forever...          1.0   \n",
       "112124  I will date ANY femoid: they CANNOT be forever...          1.0   \n",
       "112125  I will date ANY femoid: they CANNOT be forever...          1.0   \n",
       "112126  I will date ANY femoid: they CANNOT be forever...          1.0   \n",
       "\n",
       "        post_split  \n",
       "118              3  \n",
       "119              3  \n",
       "120              3  \n",
       "121              3  \n",
       "236              4  \n",
       "...            ...  \n",
       "111926           3  \n",
       "112123           6  \n",
       "112124           6  \n",
       "112125           6  \n",
       "112126           6  \n",
       "\n",
       "[2264 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simple[df_simple['post_split']>2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b97d4afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sep = ': '\n",
    "stripped = x.split(sep, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac2a96c",
   "metadata": {},
   "source": [
    "#### Text structure observations:\n",
    "- Observing structure in social media comment reply\n",
    "- Observing number/character series representing emoji at the end of post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0755e02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @JETzLyfe412: Started off wit nuttin I was hungry, now I got a couple niggas bitches who want me'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d61ea77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT @JETzLyfe412',\n",
       " 'Started off wit nuttin I was hungry, now I got a couple niggas bitches who want me']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stripped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a29cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "x =df_simple.iloc[118,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cde7e0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"RT @prettykells: &#8220;@100046729: That's fucked up when a bitch you fw , down talk you.. Then with hoes they claim they don't fw &#128080; funny.&#8221;&#8252;&#65039;&#8252;&#65039;&#8230;\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf4f9a7",
   "metadata": {},
   "source": [
    "### Regex Cleaning based on observed pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08c00358",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's fucked up when a bitch you fw , down talk you.. Then with hoes they claim they don't fw &#128080; funny.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = '^RT.*: '\n",
    "pattern_2 ='&#[^a-zA-Z]+;$'\n",
    "re.sub(pattern_2,'',re.sub(pattern,'',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fceffa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple['clean_post']=[re.sub(pattern_2,'',re.sub(pattern,'',x)) for x in df_simple['post']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25d82d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple['label']= [x if x!=0.5 else 3 for x in df_simple['offensiveYN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8d9c913",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post</th>\n",
       "      <th>offensiveYN</th>\n",
       "      <th>clean_post</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I'm convinced that some of y'all bitches get p...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>I'm convinced that some of y'all bitches get p...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>I'm convinced that some of y'all bitches get p...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You f...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Stupid fucking nigger LeBron. You flopping stu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You f...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Stupid fucking nigger LeBron. You flopping stu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112895</th>\n",
       "      <td>Thought you fellas might like to explain to so...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thought you fellas might like to explain to so...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112896</th>\n",
       "      <td>Thought you fellas might like to explain to so...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thought you fellas might like to explain to so...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112897</th>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112898</th>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112899</th>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112900 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     post  offensiveYN  \\\n",
       "0       RT @_LexC__: I'm convinced that some of y'all ...          1.0   \n",
       "1       RT @_LexC__: I'm convinced that some of y'all ...          0.5   \n",
       "2       RT @_LexC__: I'm convinced that some of y'all ...          0.5   \n",
       "3       RT @iBeZo: Stupid fucking nigger LeBron. You f...          1.0   \n",
       "4       RT @iBeZo: Stupid fucking nigger LeBron. You f...          1.0   \n",
       "...                                                   ...          ...   \n",
       "112895  Thought you fellas might like to explain to so...          1.0   \n",
       "112896  Thought you fellas might like to explain to so...          0.0   \n",
       "112897  If female voters were discounted, Labour would...          0.0   \n",
       "112898  If female voters were discounted, Labour would...          0.0   \n",
       "112899  If female voters were discounted, Labour would...          0.5   \n",
       "\n",
       "                                               clean_post  label  \n",
       "0       I'm convinced that some of y'all bitches get p...    1.0  \n",
       "1       I'm convinced that some of y'all bitches get p...    3.0  \n",
       "2       I'm convinced that some of y'all bitches get p...    3.0  \n",
       "3       Stupid fucking nigger LeBron. You flopping stu...    1.0  \n",
       "4       Stupid fucking nigger LeBron. You flopping stu...    1.0  \n",
       "...                                                   ...    ...  \n",
       "112895  Thought you fellas might like to explain to so...    1.0  \n",
       "112896  Thought you fellas might like to explain to so...    0.0  \n",
       "112897  If female voters were discounted, Labour would...    0.0  \n",
       "112898  If female voters were discounted, Labour would...    0.0  \n",
       "112899  If female voters were discounted, Labour would...    3.0  \n",
       "\n",
       "[112900 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec4218e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d8f801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_simple.to_csv('trn_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "202e7a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple = pd.read_csv('trn_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6931912e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>post</th>\n",
       "      <th>offensiveYN</th>\n",
       "      <th>clean_post</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I'm convinced that some of y'all bitches get p...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>I'm convinced that some of y'all bitches get p...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>I'm convinced that some of y'all bitches get p...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You f...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Stupid fucking nigger LeBron. You flopping stu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You f...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Stupid fucking nigger LeBron. You flopping stu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               post  offensiveYN  \\\n",
       "0           0  RT @_LexC__: I'm convinced that some of y'all ...          1.0   \n",
       "1           1  RT @_LexC__: I'm convinced that some of y'all ...          0.5   \n",
       "2           2  RT @_LexC__: I'm convinced that some of y'all ...          0.5   \n",
       "3           3  RT @iBeZo: Stupid fucking nigger LeBron. You f...          1.0   \n",
       "4           4  RT @iBeZo: Stupid fucking nigger LeBron. You f...          1.0   \n",
       "\n",
       "                                          clean_post  label  \n",
       "0  I'm convinced that some of y'all bitches get p...    1.0  \n",
       "1  I'm convinced that some of y'all bitches get p...    3.0  \n",
       "2  I'm convinced that some of y'all bitches get p...    3.0  \n",
       "3  Stupid fucking nigger LeBron. You flopping stu...    1.0  \n",
       "4  Stupid fucking nigger LeBron. You flopping stu...    1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72af1025",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df_simple['clean_post'].values\n",
    "y = df_simple['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "911230c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train,sentences_test,y_train,y_test = train_test_split(\n",
    "                                                sentences, y,  \n",
    "                                                test_size=0.20,  \n",
    "                                                random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe93613c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(sentences_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d7a9ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
    "X_test = tokenizer.texts_to_sequences(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e858bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f8cd7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d917a537",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  \n",
    "    # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word] \n",
    "                embedding_matrix[idx] = np.array(\n",
    "                                        vector, dtype=np.float32)[:embedding_dim]\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bedf3054",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "embedding_matrix = create_embedding_matrix('glove.6B.50d.txt' ,\n",
    "                                            tokenizer.word_index,  \n",
    "                                            embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354df9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a925a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d64643e6",
   "metadata": {},
   "source": [
    "### Initial training tryout\n",
    "- Without label voting scheme, the model fail to converge because the \"ground truth\" is \"too noisy\"\n",
    "- the detailed reason being that each post is labled by multiple people with different background, and their labeling may contradict\n",
    "- stopped the training prematurely based on the above observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b562f84f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "904/904 [==============================] - 309s 342ms/step - loss: nan - accuracy: 0.4135 - val_loss: nan - val_accuracy: 0.4141\n",
      "Epoch 2/5\n",
      "904/904 [==============================] - 303s 335ms/step - loss: nan - accuracy: 0.4132 - val_loss: nan - val_accuracy: 0.4141\n",
      "Epoch 3/5\n",
      "904/904 [==============================] - 298s 330ms/step - loss: nan - accuracy: 0.4132 - val_loss: nan - val_accuracy: 0.4141\n",
      "Epoch 4/5\n",
      "127/904 [===>..........................] - ETA: 4:06 - loss: nan - accuracy: 0.4139"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-13b9469a41a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m---> 15\u001b[0;31m history = model.fit(X_train, y_train,\n\u001b[0m\u001b[1;32m     16\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "embedding_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=5,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3812c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55851eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1762acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6aa2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63265e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb38003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42f1b1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52ccca6a",
   "metadata": {},
   "source": [
    "# Start of exploring voting scheme and retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dcc658",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple = pd.read_csv('trn_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9df437fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>post</th>\n",
       "      <th>offensiveYN</th>\n",
       "      <th>clean_post</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I'm convinced that some of y'all bitches get p...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>I'm convinced that some of y'all bitches get p...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @_LexC__: I'm convinced that some of y'all ...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>I'm convinced that some of y'all bitches get p...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You f...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Stupid fucking nigger LeBron. You flopping stu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You f...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Stupid fucking nigger LeBron. You flopping stu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112895</th>\n",
       "      <td>112895</td>\n",
       "      <td>Thought you fellas might like to explain to so...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thought you fellas might like to explain to so...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112896</th>\n",
       "      <td>112896</td>\n",
       "      <td>Thought you fellas might like to explain to so...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Thought you fellas might like to explain to so...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112897</th>\n",
       "      <td>112897</td>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112898</th>\n",
       "      <td>112898</td>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112899</th>\n",
       "      <td>112899</td>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>If female voters were discounted, Labour would...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112900 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                               post  \\\n",
       "0                0  RT @_LexC__: I'm convinced that some of y'all ...   \n",
       "1                1  RT @_LexC__: I'm convinced that some of y'all ...   \n",
       "2                2  RT @_LexC__: I'm convinced that some of y'all ...   \n",
       "3                3  RT @iBeZo: Stupid fucking nigger LeBron. You f...   \n",
       "4                4  RT @iBeZo: Stupid fucking nigger LeBron. You f...   \n",
       "...            ...                                                ...   \n",
       "112895      112895  Thought you fellas might like to explain to so...   \n",
       "112896      112896  Thought you fellas might like to explain to so...   \n",
       "112897      112897  If female voters were discounted, Labour would...   \n",
       "112898      112898  If female voters were discounted, Labour would...   \n",
       "112899      112899  If female voters were discounted, Labour would...   \n",
       "\n",
       "        offensiveYN                                         clean_post  label  \n",
       "0               1.0  I'm convinced that some of y'all bitches get p...    1.0  \n",
       "1               0.5  I'm convinced that some of y'all bitches get p...    3.0  \n",
       "2               0.5  I'm convinced that some of y'all bitches get p...    3.0  \n",
       "3               1.0  Stupid fucking nigger LeBron. You flopping stu...    1.0  \n",
       "4               1.0  Stupid fucking nigger LeBron. You flopping stu...    1.0  \n",
       "...             ...                                                ...    ...  \n",
       "112895          1.0  Thought you fellas might like to explain to so...    1.0  \n",
       "112896          0.0  Thought you fellas might like to explain to so...    0.0  \n",
       "112897          0.0  If female voters were discounted, Labour would...    0.0  \n",
       "112898          0.0  If female voters were discounted, Labour would...    0.0  \n",
       "112899          0.5  If female voters were discounted, Labour would...    3.0  \n",
       "\n",
       "[112900 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "513f21c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_simple.groupby(by=[\"clean_post\"]).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c30eb3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_post</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>post</th>\n",
       "      <th>offensiveYN</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\nJust watched facial recognition technology f...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I propose a new law \\n\\n Any congressman or w...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Just a partial list of the Dem playbook\\n\\nfo...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>all the liberals who are saying to get rid of...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35458</th>\n",
       "      <td>“You can drink an ugly woman pretty, faster th...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35459</th>\n",
       "      <td>“You da bomb!” “No, you da bomb!” In America –...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35469</th>\n",
       "      <td>‼️PRANK ALERT ‼️ THIS WEEKS #DolanTwinsNewVide...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35470</th>\n",
       "      <td>⁠Why do wh*te people like to play hockey?  It’...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35481</th>\n",
       "      <td>⚽️ POLL: After an eventful day in the #Champio...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6320 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clean_post  Unnamed: 0  post  \\\n",
       "8      \\nJust watched facial recognition technology f...           7     7   \n",
       "20      I propose a new law \\n\\n Any congressman or w...           6     6   \n",
       "23      Just a partial list of the Dem playbook\\n\\nfo...           5     5   \n",
       "26      all the liberals who are saying to get rid of...           4     4   \n",
       "29     !!! RT @mayasolovely: As a woman you shouldn't...           4     4   \n",
       "...                                                  ...         ...   ...   \n",
       "35458  “You can drink an ugly woman pretty, faster th...           6     6   \n",
       "35459  “You da bomb!” “No, you da bomb!” In America –...           6     6   \n",
       "35469  ‼️PRANK ALERT ‼️ THIS WEEKS #DolanTwinsNewVide...           6     6   \n",
       "35470  ⁠Why do wh*te people like to play hockey?  It’...           4     4   \n",
       "35481  ⚽️ POLL: After an eventful day in the #Champio...           6     6   \n",
       "\n",
       "       offensiveYN  label  \n",
       "8                7      7  \n",
       "20               6      6  \n",
       "23               5      5  \n",
       "26               4      4  \n",
       "29               4      4  \n",
       "...            ...    ...  \n",
       "35458            6      6  \n",
       "35459            6      6  \n",
       "35469            6      6  \n",
       "35470            4      4  \n",
       "35481            6      6  \n",
       "\n",
       "[6320 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg[df_agg['post']>3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6087826",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_agg['post'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d6b6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2017 na value for offensiveYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d810544",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple = df_simple[df_simple['offensiveYN'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60143782",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_simple.groupby(by=[\"clean_post\"])['offensiveYN'].agg(lambda x:pd.Series.mode(x)[0]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06ff807a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_post</th>\n",
       "      <th>offensiveYN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nBill Kristol and Ben Shaprio, two turds in...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nRose\\n🌹Taylor‏ @RealRoseTaylor 6h6 hours a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nCharlie Kirk‏\\n\\nJohnny Depp calls for death...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDavid Knight‏ \\n\\nNotice how quickly things ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nFinland fireball: Time-lapse video shows nig...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35414</th>\n",
       "      <td>👉 Illegally in the country after 5 deportation...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35415</th>\n",
       "      <td>💥Breaking💥\\nJulian Assange is the gate keeper ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35416</th>\n",
       "      <td>📖 2Kings 22:19  because your heart was peniten...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35417</th>\n",
       "      <td>🚨#FAKENEWSAWARDS🚨\\n\\n🚨 who is #1 fake news ?🚨\\...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35418</th>\n",
       "      <td>🚨BREAKING: illegal alien 5x deported on 7 felo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35419 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clean_post  offensiveYN\n",
       "0      \\n\\nBill Kristol and Ben Shaprio, two turds in...          1.0\n",
       "1      \\n\\nRose\\n🌹Taylor‏ @RealRoseTaylor 6h6 hours a...          0.0\n",
       "2      \\nCharlie Kirk‏\\n\\nJohnny Depp calls for death...          1.0\n",
       "3      \\nDavid Knight‏ \\n\\nNotice how quickly things ...          0.0\n",
       "4      \\nFinland fireball: Time-lapse video shows nig...          0.0\n",
       "...                                                  ...          ...\n",
       "35414  👉 Illegally in the country after 5 deportation...          0.0\n",
       "35415  💥Breaking💥\\nJulian Assange is the gate keeper ...          0.0\n",
       "35416  📖 2Kings 22:19  because your heart was peniten...          0.0\n",
       "35417  🚨#FAKENEWSAWARDS🚨\\n\\n🚨 who is #1 fake news ?🚨\\...          0.0\n",
       "35418  🚨BREAKING: illegal alien 5x deported on 7 felo...          1.0\n",
       "\n",
       "[35419 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b896c4b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\n\\nBill Kristol and Ben Shaprio, two turds in the same toilet bowl.\\n\\n',\n",
       "       \"\\n\\nRose\\n🌹Taylor\\u200f @RealRoseTaylor 6h6 hours ago\\n\\nNewt nails it 🎯\\n\\n🇺🇸Say what you will about @POTUS style, you can't deny how effective he is 💪🏻\\n\\n#SundayMorning #MAGA\\npic.twitter.com/s6o89Yg9PT\\n\",\n",
       "       '\\nCharlie Kirk\\u200f\\n\\nJohnny Depp calls for death of Trump -- left says it\\'s \"free speech\"\\n\\nConservatives come to campus to speak -- left calls it \"hate speech\"\\n',\n",
       "       ...,\n",
       "       '📖 2Kings 22:19  because your heart was penitent, and you humbled yourself before the LORD, ... and you have torn your clothes and wept before me, I also have heard you, declares the LORD.',\n",
       "       '🚨#FAKENEWSAWARDS🚨\\n\\n🚨 who is\\xa0#1\\xa0fake news ?🚨\\n\\n🚨which 1 of these?⬇⬇🚨',\n",
       "       '🚨BREAKING: illegal alien 5x deported on 7 felonies found not guilty in the murder of Kate Steinle who he shot with a gun\\n\\nJury full of communists just allowed a foreigner to execute an American citizen without repercussion\\n\\nThis is a glimpse into the future if we don’t take drastic measures'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg['clean_post']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9347987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg['label']= [x if x!=0.5 else 3 for x in df_agg['offensiveYN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b566073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c049156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df_agg['clean_post'].values\n",
    "#y = df_agg['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6fa2ba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df_agg['label'].values)\n",
    "#test_y = le.transform(test_y.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d35a14d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99a46da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train,sentences_test,y_train,y_test = train_test_split(\n",
    "                                                sentences, y,  \n",
    "                                                test_size=0.20,  \n",
    "                                                random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0e1d2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 3)\n",
    "y_test = to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "98e359aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b40f9065",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(sentences_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b47da98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
    "X_test = tokenizer.texts_to_sequences(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4eeef786",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e1d68adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c4490d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  \n",
    "    # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word] \n",
    "                embedding_matrix[idx] = np.array(\n",
    "                                        vector, dtype=np.float32)[:embedding_dim]\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d13b3fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "embedding_matrix = create_embedding_matrix('glove.6B.50d.txt' ,\n",
    "                                            tokenizer.word_index,  \n",
    "                                            embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fdf14d",
   "metadata": {},
   "outputs": [],
   "source": [
    " = Conv1D(128, 3, activation='relu')(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Conv1D(128, 3, activation='relu')(x)\n",
    "x = MaxPooling1D(3)(x)\n",
    "x = Conv1D(128, 3, activation='relu')(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(len(possible_labels), activation='sigmoid')(x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94156819",
   "metadata": {},
   "source": [
    "### Recording below as baseline performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9fea49c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5667/5667 [==============================] - 323s 57ms/step - loss: 0.7222 - accuracy: 0.7010 - val_loss: 0.6723 - val_accuracy: 0.7326\n",
      "Epoch 2/5\n",
      "5667/5667 [==============================] - 323s 57ms/step - loss: 0.6067 - accuracy: 0.7659 - val_loss: 0.6923 - val_accuracy: 0.7349\n",
      "Epoch 3/5\n",
      "5667/5667 [==============================] - 324s 57ms/step - loss: 0.5166 - accuracy: 0.8050 - val_loss: 0.7212 - val_accuracy: 0.7276\n",
      "Epoch 4/5\n",
      "5667/5667 [==============================] - 323s 57ms/step - loss: 0.4177 - accuracy: 0.8451 - val_loss: 0.8624 - val_accuracy: 0.7158\n",
      "Epoch 5/5\n",
      "5667/5667 [==============================] - 319s 56ms/step - loss: 0.3264 - accuracy: 0.8753 - val_loss: 0.9675 - val_accuracy: 0.7023\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "embedding_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=5,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3ee98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### incorporate numeric features/ categorical features\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
