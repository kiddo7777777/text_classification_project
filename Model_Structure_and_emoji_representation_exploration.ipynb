{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cae1173f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad8d55c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple = pd.read_csv('trn_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "643213c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_simple = df_simple[df_simple['offensiveYN'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4ce2c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_simple.groupby(by=[\"clean_post\"])['offensiveYN'].agg(lambda x:pd.Series.mode(x)[0]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26601e9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_post</th>\n",
       "      <th>offensiveYN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nBill Kristol and Ben Shaprio, two turds in...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nCharlie Kirk‚Äè\\n\\nJohnny Depp calls for death...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDavid Knight‚Äè \\n\\nNotice how quickly things ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nFinland fireball: Time-lapse video shows nig...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35414</th>\n",
       "      <td>üëâ Illegally in the country after 5 deportation...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35415</th>\n",
       "      <td>üí•Breakingüí•\\nJulian Assange is the gate keeper ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35416</th>\n",
       "      <td>üìñ 2Kings 22:19  because your heart was peniten...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35417</th>\n",
       "      <td>üö®#FAKENEWSAWARDSüö®\\n\\nüö® who is¬†#1¬†fake news ?üö®\\...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35418</th>\n",
       "      <td>üö®BREAKING: illegal alien 5x deported on 7 felo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35419 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clean_post  offensiveYN\n",
       "0      \\n\\nBill Kristol and Ben Shaprio, two turds in...          1.0\n",
       "1      \\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...          0.0\n",
       "2      \\nCharlie Kirk‚Äè\\n\\nJohnny Depp calls for death...          1.0\n",
       "3      \\nDavid Knight‚Äè \\n\\nNotice how quickly things ...          0.0\n",
       "4      \\nFinland fireball: Time-lapse video shows nig...          0.0\n",
       "...                                                  ...          ...\n",
       "35414  üëâ Illegally in the country after 5 deportation...          0.0\n",
       "35415  üí•Breakingüí•\\nJulian Assange is the gate keeper ...          0.0\n",
       "35416  üìñ 2Kings 22:19  because your heart was peniten...          0.0\n",
       "35417  üö®#FAKENEWSAWARDSüö®\\n\\nüö® who is¬†#1¬†fake news ?üö®\\...          0.0\n",
       "35418  üö®BREAKING: illegal alien 5x deported on 7 felo...          1.0\n",
       "\n",
       "[35419 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7862f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6f3a3df",
   "metadata": {},
   "source": [
    "### Explore emoji representation by translating emoji to english word using package and out sourced word_emoji matching dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601c7ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "753319f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emot\n",
      "  Downloading emot-3.1-py3-none-any.whl (61 kB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 61 kB 17 kB/s  eta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: emot\n",
      "Successfully installed emot-3.1\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/hwu24/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install emot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fbc98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "from emot.emo_unicode import EMOJI_UNICODE, UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26375b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Emoji_Dict.p', 'rb') as fp:\n",
    "    Emoji_Dict = pickle.load(fp)\n",
    "Emoji_Dict = {v: k for k, v in Emoji_Dict.items()}\n",
    "\n",
    "def convert_emojis_to_word(text):\n",
    "    for emot in Emoji_Dict:\n",
    "        text = re.sub(r'('+emot+')', \"_\".join(Emoji_Dict[emot].replace(\",\",\"\").replace(\":\",\"\").split()), text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a635b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emojis(text):\n",
    "    for emot in UNICODE_EMOJI:\n",
    "        text = text.replace(emot, \"_\".join(UNICODE_EMOJI[emot].replace(\",\",\"\").replace(\":\",\"\").split()))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a141fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '\\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e852d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nRose\\nroseTaylor\\u200f @RealRoseTaylor 6h6'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_emojis(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34189636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nRose\\nroseTaylor\\u200f @RealRoseTaylor 6h6'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_emojis_to_word(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "959d1fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_post</th>\n",
       "      <th>offensiveYN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nBill Kristol and Ben Shaprio, two turds in...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nCharlie Kirk‚Äè\\n\\nJohnny Depp calls for death...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nDavid Knight‚Äè \\n\\nNotice how quickly things ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nFinland fireball: Time-lapse video shows nig...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35414</th>\n",
       "      <td>üëâ Illegally in the country after 5 deportation...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35415</th>\n",
       "      <td>üí•Breakingüí•\\nJulian Assange is the gate keeper ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35416</th>\n",
       "      <td>üìñ 2Kings 22:19  because your heart was peniten...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35417</th>\n",
       "      <td>üö®#FAKENEWSAWARDSüö®\\n\\nüö® who is¬†#1¬†fake news ?üö®\\...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35418</th>\n",
       "      <td>üö®BREAKING: illegal alien 5x deported on 7 felo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35419 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clean_post  offensiveYN\n",
       "0      \\n\\nBill Kristol and Ben Shaprio, two turds in...          1.0\n",
       "1      \\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...          0.0\n",
       "2      \\nCharlie Kirk‚Äè\\n\\nJohnny Depp calls for death...          1.0\n",
       "3      \\nDavid Knight‚Äè \\n\\nNotice how quickly things ...          0.0\n",
       "4      \\nFinland fireball: Time-lapse video shows nig...          0.0\n",
       "...                                                  ...          ...\n",
       "35414  üëâ Illegally in the country after 5 deportation...          0.0\n",
       "35415  üí•Breakingüí•\\nJulian Assange is the gate keeper ...          0.0\n",
       "35416  üìñ 2Kings 22:19  because your heart was peniten...          0.0\n",
       "35417  üö®#FAKENEWSAWARDSüö®\\n\\nüö® who is¬†#1¬†fake news ?üö®\\...          0.0\n",
       "35418  üö®BREAKING: illegal alien 5x deported on 7 felo...          1.0\n",
       "\n",
       "[35419 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f1604cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg['post_emo_replace'] = df_agg['clean_post'].map(lambda x: convert_emojis_to_word(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68c27852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_agg.to_csv('no_emoji.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba555636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.68374061584473"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start  = time.time()\n",
    "# x = [convert_emojis_to_word(text) for text in df_agg['clean_post'][:1000]]\n",
    "# end = time.time()\n",
    "# end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "279c79d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0768e377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1637093986.8992023"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19f91ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d846c491",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df_agg['post_emo_replace'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38e66e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(df_agg['offensiveYN'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1668250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train,sentences_test,y_train,y_test = train_test_split(\n",
    "                                                sentences, y,  \n",
    "                                                test_size=0.20,  \n",
    "                                                random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f8ff1a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, 3)\n",
    "y_test = to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "596d6a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(sentences_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8aa1722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(sentences_train)\n",
    "X_test = tokenizer.texts_to_sequences(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28099e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "881b3d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1dab34e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  \n",
    "    # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word] \n",
    "                embedding_matrix[idx] = np.array(\n",
    "                                        vector, dtype=np.float32)[:embedding_dim]\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ac3fb938",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "embedding_matrix = create_embedding_matrix('glove.6B.50d.txt' ,\n",
    "                                            tokenizer.word_index,  \n",
    "                                            embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07ca27e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5667/5667 [==============================] - 374s 66ms/step - loss: 0.7265 - accuracy: 0.6992 - val_loss: 0.6750 - val_accuracy: 0.7315\n",
      "Epoch 2/5\n",
      "5667/5667 [==============================] - 344s 61ms/step - loss: 0.6118 - accuracy: 0.7638 - val_loss: 0.6949 - val_accuracy: 0.7256\n",
      "Epoch 3/5\n",
      "5667/5667 [==============================] - 347s 61ms/step - loss: 0.5211 - accuracy: 0.8038 - val_loss: 0.7325 - val_accuracy: 0.7222\n",
      "Epoch 4/5\n",
      "5667/5667 [==============================] - 347s 61ms/step - loss: 0.4148 - accuracy: 0.8444 - val_loss: 0.8217 - val_accuracy: 0.7173\n",
      "Epoch 5/5\n",
      "5667/5667 [==============================] - 347s 61ms/step - loss: 0.3226 - accuracy: 0.8761 - val_loss: 1.0811 - val_accuracy: 0.7029\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "embedding_dim = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=maxlen))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(layers.GlobalMaxPooling1D())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=5,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c11bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083b5ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7051bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc6c959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d48b85d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fc061b9",
   "metadata": {},
   "source": [
    "## Explore model structure by feeding  demographic features\n",
    "- Utilize text concatenation to combine post and categorical demographic data and feed the concatenated version of text to embedding layer for feature extraction and model learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d3478f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.read_csv('SBF_trn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0082b7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_trn[['post','annotatorGender','annotatorRace','annotatorAge','offensiveYN']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf6aefb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112900, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c14e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '^RT.*: '\n",
    "pattern_2 ='&#[^a-zA-Z]+;$'\n",
    "#re.sub(pattern_2,'',re.sub(pattern,'',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b114cbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['clean_post']=[re.sub(pattern_2,'',re.sub(pattern,'',x)) for x in df_full['post']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d51ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_full[df_full['offensiveYN'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d8dbbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['label']= [x if x!=0.5 else 3 for x in df_full['offensiveYN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43ca9f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110883, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9763d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_agg = df_full.groupby(by=[\"clean_post\",'annotatorGender','annotatorRace','annotatorAge','offensiveYN']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04dd7841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88822, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "688667bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_agg = df_full.groupby(by=[\"clean_post\",'annotatorGender','annotatorRace','annotatorAge'])['offensiveYN'].agg(lambda x:pd.Series.mode(x)[0]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f56e9445",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_post</th>\n",
       "      <th>annotatorGender</th>\n",
       "      <th>annotatorRace</th>\n",
       "      <th>annotatorAge</th>\n",
       "      <th>offensiveYN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nBill Kristol and Ben Shaprio, two turds in...</td>\n",
       "      <td>man</td>\n",
       "      <td>white</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nBill Kristol and Ben Shaprio, two turds in...</td>\n",
       "      <td>man</td>\n",
       "      <td>white</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\nBill Kristol and Ben Shaprio, two turds in...</td>\n",
       "      <td>woman</td>\n",
       "      <td>white</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...</td>\n",
       "      <td>man</td>\n",
       "      <td>white</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...</td>\n",
       "      <td>woman</td>\n",
       "      <td>white</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_post annotatorGender  \\\n",
       "0  \\n\\nBill Kristol and Ben Shaprio, two turds in...             man   \n",
       "1  \\n\\nBill Kristol and Ben Shaprio, two turds in...             man   \n",
       "2  \\n\\nBill Kristol and Ben Shaprio, two turds in...           woman   \n",
       "3  \\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...             man   \n",
       "4  \\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...           woman   \n",
       "\n",
       "  annotatorRace  annotatorAge  offensiveYN  \n",
       "0         white          41.0          1.0  \n",
       "1         white          42.0          1.0  \n",
       "2         white          39.0          1.0  \n",
       "3         white          25.0          0.0  \n",
       "4         white          30.0          0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "329c0565",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_agg['annotatorGender']= [' '+ x for x in df_full_agg['annotatorGender']]\n",
    "df_full_agg['annotatorRace']= [' '+ x for x in df_full_agg['annotatorRace']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0672d648",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_agg['concate']= df_full_agg['clean_post']+df_full_agg['annotatorGender']+df_full_agg['annotatorRace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e61a7c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_agg =df_full_agg[['concate','annotatorAge','offensiveYN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c9e6323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88465, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_agg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dbfee2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concate</th>\n",
       "      <th>annotatorAge</th>\n",
       "      <th>offensiveYN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nBill Kristol and Ben Shaprio, two turds in...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nBill Kristol and Ben Shaprio, two turds in...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\nBill Kristol and Ben Shaprio, two turds in...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             concate  annotatorAge  \\\n",
       "0  \\n\\nBill Kristol and Ben Shaprio, two turds in...          41.0   \n",
       "1  \\n\\nBill Kristol and Ben Shaprio, two turds in...          42.0   \n",
       "2  \\n\\nBill Kristol and Ben Shaprio, two turds in...          39.0   \n",
       "3  \\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...          25.0   \n",
       "4  \\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...          30.0   \n",
       "\n",
       "   offensiveYN  \n",
       "0          1.0  \n",
       "1          1.0  \n",
       "2          1.0  \n",
       "3          0.0  \n",
       "4          0.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "041a1c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(df_full_agg, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "064dd47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(train['offensiveYN'].values, 3)\n",
    "y_test = to_categorical(test['offensiveYN'].values, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b68f41f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = train['concate'].values\n",
    "num_train = train['annotatorAge'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e8b539c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = test['concate'].values\n",
    "num_test = test['annotatorAge'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6a9061d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = tokenizer.texts_to_sequences(text_train)\n",
    "X_test_text = tokenizer.texts_to_sequences(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "019d5757",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4f51e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = pad_sequences(X_train_text, padding='post', maxlen=maxlen)\n",
    "X_test_text = pad_sequences(X_test_text, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "24a39fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70772, 100)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "46f1f360",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "embedding_matrix = create_embedding_matrix('glove.6B.50d.txt' ,\n",
    "                                            tokenizer.word_index,  \n",
    "                                            embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6ac166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921e3b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f10931c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4ab197b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "14155/14155 [==============================] - 497s 35ms/step - loss: 0.5072 - accuracy: 0.7578 - val_loss: 0.4516 - val_accuracy: 0.7915\n",
      "Epoch 2/5\n",
      "14155/14155 [==============================] - 500s 35ms/step - loss: 0.4167 - accuracy: 0.8115 - val_loss: 0.4418 - val_accuracy: 0.8011\n",
      "Epoch 3/5\n",
      "14155/14155 [==============================] - 497s 35ms/step - loss: 0.3646 - accuracy: 0.8398 - val_loss: 0.4376 - val_accuracy: 0.8025\n",
      "Epoch 4/5\n",
      "14155/14155 [==============================] - 489s 35ms/step - loss: 0.3260 - accuracy: 0.8600 - val_loss: 0.4531 - val_accuracy: 0.8049\n",
      "Epoch 5/5\n",
      "14155/14155 [==============================] - 490s 35ms/step - loss: 0.2947 - accuracy: 0.8729 - val_loss: 0.4539 - val_accuracy: 0.8069\n"
     ]
    }
   ],
   "source": [
    "inp_cat_data = keras.layers.Input(shape=(X_train_text.shape[1],))\n",
    "inp_num_data = keras.layers.Input(shape=(1,))\n",
    "emb= keras.layers.Embedding(vocab_size, embedding_dim, input_length=maxlen)(inp_cat_data)\n",
    "conv_1 = keras.layers.Conv1D(128, 5, activation='relu')(emb)\n",
    "conv_2 = keras.layers.Conv1D(128, 5, activation='relu')(conv_1)\n",
    "pool = keras.layers.GlobalMaxPooling1D()(conv_2)\n",
    "flatten = keras.layers.Flatten()(pool)\n",
    "conc = keras.layers.Concatenate()([flatten, inp_num_data])\n",
    "Dense_1 = keras.layers.Dense(128, activation='relu')(conc)\n",
    "out = keras.layers.Dense(3, activation='sigmoid')(Dense_1)\n",
    "\n",
    "model = keras.Model(inputs=[inp_cat_data, inp_num_data], outputs=out)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit([X_train_text,num_train], y_train,\n",
    "                    epochs=5,\n",
    "                    validation_data=([X_test_text,num_test], y_test),\n",
    "                    batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c473b89b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8de36d11",
   "metadata": {},
   "source": [
    "## Explore model structure by feeding demographic features with 2 different pipeline\n",
    "- Created categorical embedding as well as text embedding for the existing features\n",
    "- flattened and concategated the 3 type of data (text, categorical, numeric demographic) and feed to the dense layers for model learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "390de62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8b439522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_post</th>\n",
       "      <th>annotatorAge</th>\n",
       "      <th>offensiveYN</th>\n",
       "      <th>annotatorGender_man</th>\n",
       "      <th>annotatorGender_na</th>\n",
       "      <th>annotatorGender_nonBinary</th>\n",
       "      <th>annotatorGender_transman</th>\n",
       "      <th>annotatorGender_woman</th>\n",
       "      <th>annotatorRace_asian</th>\n",
       "      <th>annotatorRace_black</th>\n",
       "      <th>annotatorRace_hisp</th>\n",
       "      <th>annotatorRace_na</th>\n",
       "      <th>annotatorRace_native</th>\n",
       "      <th>annotatorRace_other</th>\n",
       "      <th>annotatorRace_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nBill Kristol and Ben Shaprio, two turds in...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nBill Kristol and Ben Shaprio, two turds in...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\nBill Kristol and Ben Shaprio, two turds in...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88460</th>\n",
       "      <td>üìñ 2Kings 22:19  because your heart was peniten...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88461</th>\n",
       "      <td>üö®#FAKENEWSAWARDSüö®\\n\\nüö® who is¬†#1¬†fake news ?üö®\\...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88462</th>\n",
       "      <td>üö®#FAKENEWSAWARDSüö®\\n\\nüö® who is¬†#1¬†fake news ?üö®\\...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88463</th>\n",
       "      <td>üö®#FAKENEWSAWARDSüö®\\n\\nüö® who is¬†#1¬†fake news ?üö®\\...</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88464</th>\n",
       "      <td>üö®BREAKING: illegal alien 5x deported on 7 felo...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88465 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clean_post  annotatorAge  \\\n",
       "0      \\n\\nBill Kristol and Ben Shaprio, two turds in...          41.0   \n",
       "1      \\n\\nBill Kristol and Ben Shaprio, two turds in...          42.0   \n",
       "2      \\n\\nBill Kristol and Ben Shaprio, two turds in...          39.0   \n",
       "3      \\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...          25.0   \n",
       "4      \\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...          30.0   \n",
       "...                                                  ...           ...   \n",
       "88460  üìñ 2Kings 22:19  because your heart was peniten...          35.0   \n",
       "88461  üö®#FAKENEWSAWARDSüö®\\n\\nüö® who is¬†#1¬†fake news ?üö®\\...          29.0   \n",
       "88462  üö®#FAKENEWSAWARDSüö®\\n\\nüö® who is¬†#1¬†fake news ?üö®\\...          34.0   \n",
       "88463  üö®#FAKENEWSAWARDSüö®\\n\\nüö® who is¬†#1¬†fake news ?üö®\\...          49.0   \n",
       "88464  üö®BREAKING: illegal alien 5x deported on 7 felo...          28.0   \n",
       "\n",
       "       offensiveYN  annotatorGender_man  annotatorGender_na  \\\n",
       "0              1.0                    1                   0   \n",
       "1              1.0                    1                   0   \n",
       "2              1.0                    0                   0   \n",
       "3              0.0                    1                   0   \n",
       "4              0.0                    0                   0   \n",
       "...            ...                  ...                 ...   \n",
       "88460          0.0                    0                   0   \n",
       "88461          1.0                    0                   0   \n",
       "88462          0.5                    0                   0   \n",
       "88463          0.0                    0                   0   \n",
       "88464          1.0                    0                   0   \n",
       "\n",
       "       annotatorGender_nonBinary  annotatorGender_transman  \\\n",
       "0                              0                         0   \n",
       "1                              0                         0   \n",
       "2                              0                         0   \n",
       "3                              0                         0   \n",
       "4                              0                         0   \n",
       "...                          ...                       ...   \n",
       "88460                          0                         0   \n",
       "88461                          0                         0   \n",
       "88462                          0                         0   \n",
       "88463                          0                         0   \n",
       "88464                          0                         0   \n",
       "\n",
       "       annotatorGender_woman  annotatorRace_asian  annotatorRace_black  \\\n",
       "0                          0                    0                    0   \n",
       "1                          0                    0                    0   \n",
       "2                          1                    0                    0   \n",
       "3                          0                    0                    0   \n",
       "4                          1                    0                    0   \n",
       "...                      ...                  ...                  ...   \n",
       "88460                      1                    0                    0   \n",
       "88461                      1                    0                    0   \n",
       "88462                      1                    0                    0   \n",
       "88463                      1                    0                    0   \n",
       "88464                      1                    0                    0   \n",
       "\n",
       "       annotatorRace_hisp  annotatorRace_na  annotatorRace_native  \\\n",
       "0                       0                 0                     0   \n",
       "1                       0                 0                     0   \n",
       "2                       0                 0                     0   \n",
       "3                       0                 0                     0   \n",
       "4                       0                 0                     0   \n",
       "...                   ...               ...                   ...   \n",
       "88460                   0                 0                     0   \n",
       "88461                   1                 0                     0   \n",
       "88462                   0                 0                     0   \n",
       "88463                   0                 0                     0   \n",
       "88464                   0                 0                     0   \n",
       "\n",
       "       annotatorRace_other  annotatorRace_white  \n",
       "0                        0                    1  \n",
       "1                        0                    1  \n",
       "2                        0                    1  \n",
       "3                        0                    1  \n",
       "4                        0                    1  \n",
       "...                    ...                  ...  \n",
       "88460                    0                    1  \n",
       "88461                    0                    0  \n",
       "88462                    0                    1  \n",
       "88463                    0                    1  \n",
       "88464                    0                    1  \n",
       "\n",
       "[88465 rows x 15 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "efb39196",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_agg = pd.get_dummies(df_full_agg, columns = ['annotatorGender','annotatorRace'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e273261",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(df_full_agg, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "438da1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(train['offensiveYN'].values, 3)\n",
    "y_test = to_categorical(test['offensiveYN'].values, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8c85f9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = train['clean_post'].values\n",
    "num_train = train['annotatorAge'].values\n",
    "cat_train = train.iloc[:,3:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "90c2cf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "022fd569",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = test['clean_post'].values\n",
    "num_test = test['annotatorAge'].values\n",
    "cat_test = test.iloc[:,3:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3559c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = tokenizer.texts_to_sequences(text_train)\n",
    "X_test_text = tokenizer.texts_to_sequences(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ce6e7422",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5affb583",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = pad_sequences(X_train_text, padding='post', maxlen=maxlen)\n",
    "X_test_text = pad_sequences(X_test_text, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e1e2cb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "embedding_matrix = create_embedding_matrix('glove.6B.50d.txt' ,\n",
    "                                            tokenizer.word_index,  \n",
    "                                            embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7c9ef4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70772, 100)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "391d0ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70772, 12)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de0058b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_embedding = min(np.ceil((cat.shape[1])/2), 50 )\n",
    "cat_embedding_size = int(cat_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8ced938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6d91f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "14155/14155 [==============================] - 494s 35ms/step - loss: 0.5016 - accuracy: 0.7604 - val_loss: 0.4552 - val_accuracy: 0.7875\n",
      "Epoch 2/5\n",
      "14155/14155 [==============================] - 512s 36ms/step - loss: 0.4171 - accuracy: 0.8113 - val_loss: 0.4380 - val_accuracy: 0.7986\n",
      "Epoch 3/5\n",
      "14155/14155 [==============================] - 566s 40ms/step - loss: 0.3655 - accuracy: 0.8387 - val_loss: 0.4310 - val_accuracy: 0.8062\n",
      "Epoch 4/5\n",
      "14155/14155 [==============================] - 508s 36ms/step - loss: 0.3293 - accuracy: 0.8581 - val_loss: 0.4429 - val_accuracy: 0.8086\n",
      "Epoch 5/5\n",
      "14155/14155 [==============================] - 506s 36ms/step - loss: 0.3028 - accuracy: 0.8688 - val_loss: 0.4559 - val_accuracy: 0.8121\n"
     ]
    }
   ],
   "source": [
    "inp_text_data = keras.layers.Input(shape=(X_train_text.shape[1],))\n",
    "inp_cat_data = keras.layers.Input(shape=(cat.shape[1],))\n",
    "inp_num_data = keras.layers.Input(shape=(1,))\n",
    "emb= keras.layers.Embedding(vocab_size, embedding_dim, input_length=maxlen)(inp_text_data)\n",
    "emb_2 = keras.layers.Embedding(input_dim=cat.shape[1], output_dim=cat_embedding_size)(inp_cat_data)\n",
    "conv_1 = keras.layers.Conv1D(128, 5, activation='relu')(emb)\n",
    "conv_2 = keras.layers.Conv1D(128, 5, activation='relu')(conv_1)\n",
    "pool = keras.layers.GlobalMaxPooling1D()(conv_2)\n",
    "flatten = keras.layers.Flatten()(pool)\n",
    "flatten_2 = keras.layers.Flatten()(emb_2)\n",
    "conc = keras.layers.Concatenate()([flatten,flatten_2, inp_num_data])\n",
    "Dense_1 = keras.layers.Dense(128, activation='relu')(conc)\n",
    "out = keras.layers.Dense(3, activation='sigmoid')(Dense_1)\n",
    "\n",
    "model = keras.Model(inputs=[inp_text_data,inp_cat_data, inp_num_data], outputs=out)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit([X_train_text,cat_train,num_train], y_train,\n",
    "                    epochs=5,\n",
    "                    validation_data=([X_test_text,cat_test,num_test], y_test),\n",
    "                    batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d81e0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
