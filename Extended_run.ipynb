{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9daedb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "095e4a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  \n",
    "    # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    with open(filepath) as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word] \n",
    "                embedding_matrix[idx] = np.array(\n",
    "                                        vector, dtype=np.float32)[:embedding_dim]\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bd43c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff2ac0c8",
   "metadata": {},
   "source": [
    "### In previous explorations we found our model validation performance was still increasing after the training with limited epochs, therefore we would like to run those try out with more epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77ca281",
   "metadata": {},
   "source": [
    "## data read in and simple cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1623478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.read_csv('SBF_trn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da4ebf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_trn[['post','annotatorGender','annotatorRace','annotatorAge','offensiveYN']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87cbce3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112900, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf474228",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = '^RT.*: '\n",
    "pattern_2 ='&#[^a-zA-Z]+;$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f3ec17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['clean_post']=[re.sub(pattern_2,'',re.sub(pattern,'',x)) for x in df_full['post']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c3df612",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_full[df_full['offensiveYN'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b133e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['label']= [x if x!=0.5 else 3 for x in df_full['offensiveYN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cab74793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110883, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "798c93a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_agg = df_full.groupby(by=[\"clean_post\",'annotatorGender','annotatorRace','annotatorAge'])['offensiveYN'].agg(lambda x:pd.Series.mode(x)[0]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12e136ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88465, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full_agg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7064f3bd",
   "metadata": {},
   "source": [
    "## Construct data for training: combine categorical features with text for embedding and convolution processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11272322",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embedding_one =df_full_agg.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fc58f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embedding_one['annotatorGender']= [' '+ x for x in df_embedding_one['annotatorGender']]\n",
    "df_embedding_one['annotatorRace']= [' '+ x for x in df_embedding_one['annotatorRace']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e191d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embedding_one['concate']= df_embedding_one['clean_post']+df_embedding_one['annotatorGender']+df_embedding_one['annotatorRace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3e49cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88465, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embedding_one =df_embedding_one[['concate','annotatorAge','offensiveYN']]\n",
    "df_embedding_one.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d609688f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>concate</th>\n",
       "      <th>annotatorAge</th>\n",
       "      <th>offensiveYN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nBill Kristol and Ben Shaprio, two turds in...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nBill Kristol and Ben Shaprio, two turds in...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\nBill Kristol and Ben Shaprio, two turds in...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             concate  annotatorAge  \\\n",
       "0  \\n\\nBill Kristol and Ben Shaprio, two turds in...          41.0   \n",
       "1  \\n\\nBill Kristol and Ben Shaprio, two turds in...          42.0   \n",
       "2  \\n\\nBill Kristol and Ben Shaprio, two turds in...          39.0   \n",
       "3  \\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...          25.0   \n",
       "4  \\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...          30.0   \n",
       "\n",
       "   offensiveYN  \n",
       "0          1.0  \n",
       "1          1.0  \n",
       "2          1.0  \n",
       "3          0.0  \n",
       "4          0.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embedding_one.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eed7657",
   "metadata": {},
   "source": [
    "### setting up train test split and text feature embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28a422e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(df_embedding_one, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e29cb444",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(train['offensiveYN'].values, 3)\n",
    "y_test = to_categorical(test['offensiveYN'].values, 3)\n",
    "\n",
    "text_train = train['concate'].values\n",
    "num_train = train['annotatorAge'].values\n",
    "\n",
    "text_test = test['concate'].values\n",
    "num_test = test['annotatorAge'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34552ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "628719d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = tokenizer.texts_to_sequences(text_train)\n",
    "X_test_text = tokenizer.texts_to_sequences(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67eba907",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6411b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = pad_sequences(X_train_text, padding='post', maxlen=maxlen)\n",
    "X_test_text = pad_sequences(X_test_text, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49387c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70772, 100)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a10e41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "embedding_matrix = create_embedding_matrix('glove.6B.50d.txt' ,\n",
    "                                            tokenizer.word_index,  \n",
    "                                            embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faff79f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10460a54",
   "metadata": {},
   "source": [
    "### Feeding training data into model and monitor validation set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a24aab75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "14155/14155 [==============================] - 556s 39ms/step - loss: 0.5044 - accuracy: 0.7583 - val_loss: 0.4597 - val_accuracy: 0.7869\n",
      "Epoch 2/15\n",
      "14155/14155 [==============================] - 556s 39ms/step - loss: 0.4140 - accuracy: 0.8147 - val_loss: 0.4415 - val_accuracy: 0.7940\n",
      "Epoch 3/15\n",
      "14155/14155 [==============================] - 562s 40ms/step - loss: 0.3651 - accuracy: 0.8401 - val_loss: 0.4399 - val_accuracy: 0.8008\n",
      "Epoch 4/15\n",
      "14155/14155 [==============================] - 562s 40ms/step - loss: 0.3285 - accuracy: 0.8588 - val_loss: 0.4800 - val_accuracy: 0.8037\n",
      "Epoch 5/15\n",
      "14155/14155 [==============================] - 560s 40ms/step - loss: 0.2988 - accuracy: 0.8718 - val_loss: 0.4399 - val_accuracy: 0.8031\n",
      "Epoch 6/15\n",
      "14155/14155 [==============================] - 557s 39ms/step - loss: 0.2760 - accuracy: 0.8790 - val_loss: 0.4752 - val_accuracy: 0.8063\n",
      "Epoch 7/15\n",
      "14155/14155 [==============================] - 552s 39ms/step - loss: 0.2582 - accuracy: 0.8856 - val_loss: 0.4676 - val_accuracy: 0.8066\n",
      "Epoch 8/15\n",
      "14155/14155 [==============================] - 554s 39ms/step - loss: 0.2409 - accuracy: 0.8903 - val_loss: 0.5344 - val_accuracy: 0.8057\n",
      "Epoch 9/15\n",
      "14155/14155 [==============================] - 556s 39ms/step - loss: 0.2280 - accuracy: 0.8965 - val_loss: 0.5164 - val_accuracy: 0.7970\n",
      "Epoch 10/15\n",
      "14155/14155 [==============================] - 551s 39ms/step - loss: 0.2168 - accuracy: 0.8988 - val_loss: 0.6032 - val_accuracy: 0.7973\n",
      "Epoch 11/15\n",
      "14155/14155 [==============================] - 553s 39ms/step - loss: 0.2060 - accuracy: 0.9021 - val_loss: 0.5551 - val_accuracy: 0.7996\n",
      "Epoch 12/15\n",
      "14155/14155 [==============================] - 552s 39ms/step - loss: 0.1974 - accuracy: 0.9061 - val_loss: 0.6247 - val_accuracy: 0.8003\n",
      "Epoch 13/15\n",
      "14155/14155 [==============================] - 562s 40ms/step - loss: 0.1889 - accuracy: 0.9083 - val_loss: 0.7441 - val_accuracy: 0.7964\n",
      "Epoch 14/15\n",
      "14155/14155 [==============================] - 573s 40ms/step - loss: 0.1821 - accuracy: 0.9103 - val_loss: 0.7240 - val_accuracy: 0.7988\n",
      "Epoch 15/15\n",
      "14155/14155 [==============================] - 562s 40ms/step - loss: 0.1768 - accuracy: 0.9129 - val_loss: 0.9066 - val_accuracy: 0.7970\n"
     ]
    }
   ],
   "source": [
    "inp_cat_data = keras.layers.Input(shape=(X_train_text.shape[1],))\n",
    "inp_num_data = keras.layers.Input(shape=(1,))\n",
    "emb= keras.layers.Embedding(vocab_size, embedding_dim, input_length=maxlen)(inp_cat_data)\n",
    "conv_1 = keras.layers.Conv1D(128, 5, activation='relu')(emb)\n",
    "conv_2 = keras.layers.Conv1D(128, 5, activation='relu')(conv_1)\n",
    "pool = keras.layers.GlobalMaxPooling1D()(conv_2)\n",
    "flatten = keras.layers.Flatten()(pool)\n",
    "conc = keras.layers.Concatenate()([flatten, inp_num_data])\n",
    "Dense_1 = keras.layers.Dense(128, activation='relu')(conc)\n",
    "out = keras.layers.Dense(3, activation='sigmoid')(Dense_1)\n",
    "\n",
    "model = keras.Model(inputs=[inp_cat_data, inp_num_data], outputs=out)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit([X_train_text,num_train], y_train,\n",
    "                    epochs=15,\n",
    "                    validation_data=([X_test_text,num_test], y_test),\n",
    "                    batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ff5a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93c5db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "127b98fb",
   "metadata": {},
   "source": [
    "### Model with saperated embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e5bd8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embedding_second  = pd.get_dummies(df_full_agg, columns = ['annotatorGender','annotatorRace'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82983b3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_post</th>\n",
       "      <th>annotatorAge</th>\n",
       "      <th>offensiveYN</th>\n",
       "      <th>annotatorGender_man</th>\n",
       "      <th>annotatorGender_na</th>\n",
       "      <th>annotatorGender_nonBinary</th>\n",
       "      <th>annotatorGender_transman</th>\n",
       "      <th>annotatorGender_woman</th>\n",
       "      <th>annotatorRace_asian</th>\n",
       "      <th>annotatorRace_black</th>\n",
       "      <th>annotatorRace_hisp</th>\n",
       "      <th>annotatorRace_na</th>\n",
       "      <th>annotatorRace_native</th>\n",
       "      <th>annotatorRace_other</th>\n",
       "      <th>annotatorRace_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nBill Kristol and Ben Shaprio, two turds in...</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nBill Kristol and Ben Shaprio, two turds in...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\nBill Kristol and Ben Shaprio, two turds in...</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_post  annotatorAge  \\\n",
       "0  \\n\\nBill Kristol and Ben Shaprio, two turds in...          41.0   \n",
       "1  \\n\\nBill Kristol and Ben Shaprio, two turds in...          42.0   \n",
       "2  \\n\\nBill Kristol and Ben Shaprio, two turds in...          39.0   \n",
       "3  \\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...          25.0   \n",
       "4  \\n\\nRose\\nüåπTaylor‚Äè @RealRoseTaylor 6h6 hours a...          30.0   \n",
       "\n",
       "   offensiveYN  annotatorGender_man  annotatorGender_na  \\\n",
       "0          1.0                    1                   0   \n",
       "1          1.0                    1                   0   \n",
       "2          1.0                    0                   0   \n",
       "3          0.0                    1                   0   \n",
       "4          0.0                    0                   0   \n",
       "\n",
       "   annotatorGender_nonBinary  annotatorGender_transman  annotatorGender_woman  \\\n",
       "0                          0                         0                      0   \n",
       "1                          0                         0                      0   \n",
       "2                          0                         0                      1   \n",
       "3                          0                         0                      0   \n",
       "4                          0                         0                      1   \n",
       "\n",
       "   annotatorRace_asian  annotatorRace_black  annotatorRace_hisp  \\\n",
       "0                    0                    0                   0   \n",
       "1                    0                    0                   0   \n",
       "2                    0                    0                   0   \n",
       "3                    0                    0                   0   \n",
       "4                    0                    0                   0   \n",
       "\n",
       "   annotatorRace_na  annotatorRace_native  annotatorRace_other  \\\n",
       "0                 0                     0                    0   \n",
       "1                 0                     0                    0   \n",
       "2                 0                     0                    0   \n",
       "3                 0                     0                    0   \n",
       "4                 0                     0                    0   \n",
       "\n",
       "   annotatorRace_white  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_embedding_second.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f03a25",
   "metadata": {},
   "source": [
    "### Prepare data for model consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bedf2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = train_test_split(df_embedding_second, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00b905e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(train['offensiveYN'].values, 3)\n",
    "y_test = to_categorical(test['offensiveYN'].values, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05a941be",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train = train['clean_post'].values\n",
    "num_train = train['annotatorAge'].values\n",
    "cat_train = train.iloc[:,3:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd70674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "688bfe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = test['clean_post'].values\n",
    "num_test = test['annotatorAge'].values\n",
    "cat_test = test.iloc[:,3:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a56e17a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = tokenizer.texts_to_sequences(text_train)\n",
    "X_test_text = tokenizer.texts_to_sequences(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ef03a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "maxlen = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da6fe466",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_text = pad_sequences(X_train_text, padding='post', maxlen=maxlen)\n",
    "X_test_text = pad_sequences(X_test_text, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3a63829",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "embedding_matrix = create_embedding_matrix('glove.6B.50d.txt' ,\n",
    "                                            tokenizer.word_index,  \n",
    "                                            embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a33ea6ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70772, 100)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ec7cb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70772, 12)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "775980db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_embedding = min(np.ceil((cat_train.shape[1])/2), 50 ) ## determine categorical embedding size using conventional method\n",
    "cat_embedding_size = int(cat_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b29cc54",
   "metadata": {},
   "source": [
    "### Feeding training data into model and monitor validation set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7bc426d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "14155/14155 [==============================] - 556s 39ms/step - loss: 0.5000 - accuracy: 0.7597 - val_loss: 0.4524 - val_accuracy: 0.7918\n",
      "Epoch 2/15\n",
      "14155/14155 [==============================] - 568s 40ms/step - loss: 0.4152 - accuracy: 0.8111 - val_loss: 0.4417 - val_accuracy: 0.7988\n",
      "Epoch 3/15\n",
      "14155/14155 [==============================] - 565s 40ms/step - loss: 0.3652 - accuracy: 0.8388 - val_loss: 0.4380 - val_accuracy: 0.8041\n",
      "Epoch 4/15\n",
      "14155/14155 [==============================] - 568s 40ms/step - loss: 0.3308 - accuracy: 0.8545 - val_loss: 0.4364 - val_accuracy: 0.8062\n",
      "Epoch 5/15\n",
      "14155/14155 [==============================] - 566s 40ms/step - loss: 0.3037 - accuracy: 0.8674 - val_loss: 0.4754 - val_accuracy: 0.8099\n",
      "Epoch 6/15\n",
      "14155/14155 [==============================] - 566s 40ms/step - loss: 0.2837 - accuracy: 0.8751 - val_loss: 0.4507 - val_accuracy: 0.8076\n",
      "Epoch 7/15\n",
      "14155/14155 [==============================] - 482s 34ms/step - loss: 0.2678 - accuracy: 0.8805 - val_loss: 0.4746 - val_accuracy: 0.8123\n",
      "Epoch 8/15\n",
      "14155/14155 [==============================] - 566s 40ms/step - loss: 0.2525 - accuracy: 0.8850 - val_loss: 0.5041 - val_accuracy: 0.8045\n",
      "Epoch 9/15\n",
      "14155/14155 [==============================] - 557s 39ms/step - loss: 0.2393 - accuracy: 0.8894 - val_loss: 0.6680 - val_accuracy: 0.8112\n",
      "Epoch 10/15\n",
      "14155/14155 [==============================] - 545s 38ms/step - loss: 0.2302 - accuracy: 0.8907 - val_loss: 0.6243 - val_accuracy: 0.8064\n",
      "Epoch 11/15\n",
      "14155/14155 [==============================] - 550s 39ms/step - loss: 0.2242 - accuracy: 0.8935 - val_loss: 0.5882 - val_accuracy: 0.8053\n",
      "Epoch 12/15\n",
      "14155/14155 [==============================] - 532s 38ms/step - loss: 0.2169 - accuracy: 0.8950 - val_loss: 0.5178 - val_accuracy: 0.7985\n",
      "Epoch 13/15\n",
      "14155/14155 [==============================] - 549s 39ms/step - loss: 0.2116 - accuracy: 0.8957 - val_loss: 0.6210 - val_accuracy: 0.8049\n",
      "Epoch 14/15\n",
      "14155/14155 [==============================] - 533s 38ms/step - loss: 0.2043 - accuracy: 0.8969 - val_loss: 0.5377 - val_accuracy: 0.8061\n",
      "Epoch 15/15\n",
      "14155/14155 [==============================] - 536s 38ms/step - loss: 0.1994 - accuracy: 0.8986 - val_loss: 0.6305 - val_accuracy: 0.8031\n"
     ]
    }
   ],
   "source": [
    "inp_text_data = keras.layers.Input(shape=(X_train_text.shape[1],))\n",
    "inp_cat_data = keras.layers.Input(shape=(cat_train.shape[1],))\n",
    "inp_num_data = keras.layers.Input(shape=(1,))\n",
    "emb= keras.layers.Embedding(vocab_size, embedding_dim, input_length=maxlen)(inp_text_data)\n",
    "emb_2 = keras.layers.Embedding(input_dim=cat_train.shape[1], output_dim=cat_embedding_size)(inp_cat_data)\n",
    "conv_1 = keras.layers.Conv1D(128, 5, activation='relu')(emb)\n",
    "conv_2 = keras.layers.Conv1D(128, 5, activation='relu')(conv_1)\n",
    "pool = keras.layers.GlobalMaxPooling1D()(conv_2)\n",
    "flatten = keras.layers.Flatten()(pool)\n",
    "flatten_2 = keras.layers.Flatten()(emb_2)\n",
    "conc = keras.layers.Concatenate()([flatten,flatten_2, inp_num_data])\n",
    "Dense_1 = keras.layers.Dense(128, activation='relu')(conc)\n",
    "out = keras.layers.Dense(3, activation='sigmoid')(Dense_1)\n",
    "\n",
    "model = keras.Model(inputs=[inp_text_data,inp_cat_data, inp_num_data], outputs=out)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit([X_train_text,cat_train,num_train], y_train,\n",
    "                    epochs=15,\n",
    "                    validation_data=([X_test_text,cat_test,num_test], y_test),\n",
    "                    batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf92462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
